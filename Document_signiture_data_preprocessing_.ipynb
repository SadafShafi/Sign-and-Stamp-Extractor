{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# * Get rid of text \n",
        "# * Get rid of lines longer than x (horizontal and vertical)"
      ],
      "metadata": {
        "id": "HaEPbAgq9u7L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "* Get 2/3 of image  \n",
        "* Remove text \n",
        "* Remove Lines  \n",
        "* Template Matching  \n",
        "'''"
      ],
      "metadata": {
        "id": "Q1qXbJNxEozL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "* Get 2/3 of image\n",
        "* Template matching\n",
        "'''\n",
        "# done and failed"
      ],
      "metadata": {
        "id": "6_K5gtusGqHe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown \"19Q83vhxxxZSaveXa\""
      ],
      "metadata": {
        "id": "PADU6uFq4tze"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip images_docs.zip"
      ],
      "metadata": {
        "id": "aq1mjQZG45H9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2 \n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt \n",
        "# Load the image \n",
        "imageListTextExtracted = []\n",
        "def textDisappear(image):\n",
        "  # image = image[2*image.shape[0]//3:,:,:]    # uncomment for taking last 2/3rd of the image\n",
        "  # plt.imshow(image)\n",
        "  # plt.show()\n",
        "\n",
        "  gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "  # Apply adaptive thresholding\n",
        "  thresh = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 11, 2)\n",
        "  # Find contours\n",
        "  contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "  # Loop through contours\n",
        "  for contour in contours:\n",
        "      # Get the bounding box of the contour\n",
        "      x, y, w, h = cv2.boundingRect(contour)\n",
        "      # Compute the aspect ratio of the bounding box\n",
        "      aspect_ratio = w / float(h)\n",
        "      # Filter out contours that are too wide or too tall to be text\n",
        "      if aspect_ratio > 5 or aspect_ratio < 0.2:\n",
        "          continue\n",
        "      # Get the region of interest (ROI) corresponding to the contour\n",
        "      roi = image[y:y+h, x:x+w]\n",
        "      # Compute the average intensity of the ROI\n",
        "      avg_intensity = np.mean(roi)\n",
        "      # If the average intensity is below a threshold, assume the ROI contains readable text\n",
        "      if avg_intensity < 200:\n",
        "          # Fill the ROI with white color\n",
        "          cv2.rectangle(image, (x, y), (x+w, y+h), (255, 255, 255), -1)\n",
        "  # Display the result\n",
        "  plt.imshow(image)\n",
        "  imageListTextExtracted.append(image)\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "6ATONhFr0Zo2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "directory = '/content/images_docs/'  # replace with your directory path\n",
        "\n",
        "for filename in os.listdir(directory):\n",
        "    if filename.endswith('.jpg') or filename.endswith('.png'):  # adjust file extensions as necessary\n",
        "        image = cv2.imread(directory+filename)\n",
        "        plt.imshow(image)\n",
        "        plt.show()\n",
        "        textDisappear(image)"
      ],
      "metadata": {
        "id": "hRzrc-TB5MBF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir halftextedimg"
      ],
      "metadata": {
        "id": "oXYXBF_D38lo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nwpGesDXNHiU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "for num,image in enumerate(imageListTextExtracted):\n",
        "  image = Image.fromarray(np.uint8(image))\n",
        "\n",
        "# Save the image as a PNG file\n",
        "  image.save('halftextedimg/'+str(num)+'_halftextedimg.jpg')"
      ],
      "metadata": {
        "id": "-lTGtob_4SZk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r halftextedimg.zip halftextedimg\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive') \n",
        "!cp halftextedimg.zip /content/drive/MyDrive/"
      ],
      "metadata": {
        "id": "HU25mlvI5uHs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image = cv2.imread('/content/image.png')\n",
        "textDisappear(image)"
      ],
      "metadata": {
        "id": "3LbbDKFQ0_oL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "image_dir = \"/content/\"\n",
        "\n",
        "for filename in os.listdir(image_dir):\n",
        "    if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
        "      \n",
        "      image = cv2.imread(filename)\n",
        "      print(\"#################################################################\")\n",
        "      plt.imshow(image)\n",
        "      plt.show()\n",
        "      print(\"++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\")\n",
        "      textDisappear(image)"
      ],
      "metadata": {
        "id": "kY5Ms3a31CAA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nR95FlLj1W0X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Docs to images**\n"
      ],
      "metadata": {
        "id": "Zb0LBi3UuzT1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install poppler-utils"
      ],
      "metadata": {
        "id": "L_dVUxyp1HTA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pdf2image"
      ],
      "metadata": {
        "id": "TwRSfTd6u-lu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip Documents\\ IDFC.zip"
      ],
      "metadata": {
        "id": "VdG1vrNZFGeW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pdf2image import convert_from_path\n",
        " \n",
        " \n",
        "# # Store Pdf with convert_from_path function\n",
        "# images = convert_from_path('766536 A1 ADVANCE.pdf')\n",
        " \n",
        "# for i in range(len(images)):\n",
        "   \n",
        "#       # Save pages as images in the pdf\n",
        "#     images[i].save('page'+ str(i) +'.jpg', 'JPEG')"
      ],
      "metadata": {
        "id": "8PZjvQ6604uU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir images_docs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2QfCz_9lG6Du",
        "outputId": "639d418c-ea1b-4dcd-cce4-77f942db91cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘images_docs’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "# import fitz  #PyMuPDF\n",
        "\n",
        "pdf_dir = \"/content/Documents IDFC/\"  # replace with actual directory path\n",
        "output_dir = \"/content/images_docs\"  # replace with actual directory path\n",
        "\n",
        "for filename in os.listdir(pdf_dir):\n",
        "    if filename.endswith(\".pdf\"):\n",
        "        print(filename)\n",
        "        # open the PDF file\n",
        "        images = convert_from_path(\"/content/Documents IDFC/\"+filename)\n",
        "        for i in range(len(images)):    \n",
        "              # Save pages as images in the pdf\n",
        "            images[i].save(filename[:-5]+'page'+ str(i) +'.jpg', 'JPEG')"
      ],
      "metadata": {
        "id": "7fQWQYkduzuF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !rm -r *.jpg"
      ],
      "metadata": {
        "id": "0dxAKqFBvA73"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mv *.jpg images_docs/"
      ],
      "metadata": {
        "id": "piiE7Q5v24-M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r images_docs.zip images_docs"
      ],
      "metadata": {
        "id": "nYLgbcKT3PS8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n41i7hnq3_ql",
        "outputId": "bec4ce03-0c1e-4452-b4e1-ab6c319b258e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp images_docs.zip /content/drive/MyDrive/"
      ],
      "metadata": {
        "id": "MS19s5as4Nkr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "cd images_docs\n",
        "ls -1 | wc -l"
      ],
      "metadata": {
        "id": "5PVvU8Xm5xPj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da6f2c17-9c75-48a4-916e-d972e7e12f59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "151\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GiYr847CIAzB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "y59q6YoUb_Ho"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PSpWcZPib_E-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Double the data with Augmentation**"
      ],
      "metadata": {
        "id": "_gF55Bh8b_dn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown \"18alTGxxxxx1JgthCwAagCH0\""
      ],
      "metadata": {
        "id": "kTcznuiucDBi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip fullDataHalftexted.zip"
      ],
      "metadata": {
        "id": "retWaRNrcdU2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !rm -r halftextedimg"
      ],
      "metadata": {
        "id": "y9BcbE5Apm7N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Preprocessing all images\n",
        "import cv2 \n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt \n",
        "# Load the image \n",
        "imageListTextExtracted = []\n",
        "def textDisappear(image):\n",
        "  # image = image[2*image.shape[0]//3:,:,:]    # uncomment for taking last 2/3rd of the image\n",
        "  # plt.imshow(image)\n",
        "  # plt.show()\n",
        "\n",
        "  gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "  # Apply adaptive thresholding\n",
        "  thresh = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 11, 2)\n",
        "  # Find contours\n",
        "  contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "  # Loop through contours\n",
        "  for contour in contours:\n",
        "      # Get the bounding box of the contour\n",
        "      x, y, w, h = cv2.boundingRect(contour)\n",
        "      # Compute the aspect ratio of the bounding box\n",
        "      aspect_ratio = w / float(h)\n",
        "      # Filter out contours that are too wide or too tall to be text\n",
        "      if aspect_ratio > 5 or aspect_ratio < 0.2:\n",
        "          continue\n",
        "      # Get the region of interest (ROI) corresponding to the contour\n",
        "      roi = image[y:y+h, x:x+w]\n",
        "      # Compute the average intensity of the ROI\n",
        "      avg_intensity = np.mean(roi)\n",
        "      # If the average intensity is below a threshold, assume the ROI contains readable text\n",
        "      if avg_intensity < 200:\n",
        "          # Fill the ROI with white color\n",
        "          cv2.rectangle(image, (x, y), (x+w, y+h), (255, 255, 255), -1)\n",
        "  # Display the result\n",
        "  # plt.imshow(image)\n",
        "  imageListTextExtracted.append(image)\n",
        "  # plt.show()"
      ],
      "metadata": {
        "id": "ifACbrrSciAC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DGwXS3rorIGu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "directory = '/content/fullDataHalftexted/images/'  # replace with your directory path\n",
        "names = []\n",
        "for filename in os.listdir(directory):\n",
        "    if filename.endswith('.jpg') or filename.endswith('.png'):  # adjust file extensions as necessary\n",
        "        # print(directory+filename)\n",
        "        image = cv2.imread(directory+filename)\n",
        "        names.append(filename)\n",
        "        # plt.imshow(image)\n",
        "        # plt.show()\n",
        "        textDisappear(image)\n",
        "\n",
        "!mkdir halftextedimg\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "for num,image101 in enumerate(imageListTextExtracted):\n",
        "  image = Image.fromarray(np.uint8(image101))\n",
        "  # print(num)\n",
        "# Save the image as a PNG file\n",
        "  try:\n",
        "    image.save('halftextedimg/'+names[num])\n",
        "  except: \n",
        "    break \n",
        "\n",
        "!rm -r fullDataHalftexted/images/*\n",
        "!mv halftextedimg/* fullDataHalftexted/images/\n",
        "!rm -r halftextedimg\n",
        "\n",
        "\n",
        "\n",
        "from glob import glob\n",
        "len(glob('/content/fullDataHalftexted/images/*'))"
      ],
      "metadata": {
        "id": "x2RbAzEIrYtJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07809009-c766-4d87-e967-48b1aa6d4e55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "150"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import shutil\n",
        "\n",
        "# Set the path to the directory containing the images and labels\n",
        "data_dir = '/content/custom_cleangb/'\n",
        "# data_dir = '/content/images_23rd_withText/'\n",
        "data_dir = '/content/fullDataHalftexted/'\n",
        "\n",
        "\n",
        "# Set the paths to the image and label directories\n",
        "image_dir = os.path.join(data_dir, 'images')\n",
        "label_dir = os.path.join(data_dir, 'labels')\n",
        "\n",
        "# Set the proportion of data to use for training, validation, and testing\n",
        "train_prop = 0.8\n",
        "val_prop = 0.2\n",
        "# test_prop = 0.2\n",
        "\n",
        "# Create the train, validation, and test directories\n",
        "train_dir = os.path.join(data_dir, 'train')\n",
        "val_dir = os.path.join(data_dir, 'val')\n",
        "# test_dir = os.path.join(data_dir, 'test')\n",
        "\n",
        "os.makedirs(train_dir, exist_ok=True)\n",
        "os.makedirs(os.path.join(train_dir, 'images'), exist_ok=True)\n",
        "os.makedirs(os.path.join(train_dir, 'labels'), exist_ok=True)\n",
        "os.makedirs(val_dir, exist_ok=True)\n",
        "os.makedirs(os.path.join(val_dir, 'images'), exist_ok=True)\n",
        "os.makedirs(os.path.join(val_dir, 'labels'), exist_ok=True)\n",
        "# os.makedirs(test_dir, exist_ok=True)\n",
        "# os.makedirs(os.path.join(test_dir, 'images'), exist_ok=True)\n",
        "# os.makedirs(os.path.join(test_dir, 'labels'), exist_ok=True)\n",
        "\n",
        "# Get a list of all the image files\n",
        "image_files = [f for f in os.listdir(image_dir) if f.endswith('.jpg')]\n",
        "\n",
        "# Shuffle the image files\n",
        "random.shuffle(image_files)\n",
        "\n",
        "# Calculate the number of images for each set\n",
        "num_images = len(image_files)\n",
        "num_train = int(num_images * train_prop)\n",
        "num_val = int(num_images * val_prop)\n",
        "# num_test = int(num_images * test_prop)\n",
        "\n",
        "# Copy the images and labels to the appropriate directories\n",
        "for i, image_file in enumerate(image_files):\n",
        "    # Get the corresponding label file\n",
        "    label_file = image_file.replace('.jpg', '.txt')\n",
        "    # Set the source paths\n",
        "    image_path = os.path.join(image_dir, image_file)\n",
        "    label_path = os.path.join(label_dir, label_file)\n",
        "    # Set the destination paths\n",
        "    if i < num_train:\n",
        "        dest_dir = train_dir\n",
        "    else:\n",
        "        dest_dir = val_dir\n",
        "    dest_image_dir = os.path.join(dest_dir, 'images')\n",
        "    dest_label_dir = os.path.join(dest_dir, 'labels')\n",
        "    dest_image_path = os.path.join(dest_image_dir, image_file)\n",
        "    dest_label_path = os.path.join(dest_label_dir, label_file)\n",
        "    # Copy the files to the appropriate directories\n",
        "    shutil.copyfile(image_path, dest_image_path)\n",
        "    shutil.copyfile(label_path, dest_label_path)\n"
      ],
      "metadata": {
        "id": "5b9cPUx4cyYW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir augImages\n",
        "!mkdir augLabels"
      ],
      "metadata": {
        "id": "YSyNKL9Ye73m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73de89e4-5ff4-4e94-b046-68b07278e957"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘augImages’: File exists\n",
            "mkdir: cannot create directory ‘augLabels’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %%bash\n",
        "# rm -r augImages/*\n",
        "# rm -r augLabels/*"
      ],
      "metadata": {
        "id": "LMQwhagVgB0b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import imgaug as ia\n",
        "from imgaug import augmenters as iaa\n",
        "from imgaug.augmentables.bbs import BoundingBox, BoundingBoxesOnImage\n",
        "\n",
        "# Define augmentation sequence\n",
        "aug = iaa.OneOf([\n",
        "    iaa.Affine(rotate=(-25, 25)),\n",
        "    iaa.Affine(shear=(-8, 8)),\n",
        "    iaa.AdditiveGaussianNoise(scale=(0, 0.1*255)),\n",
        "    iaa.Add((-50, 50), per_channel=True),\n",
        "    iaa.Multiply((0.5, 1.5), per_channel=True),\n",
        "    iaa.ContrastNormalization((0.5, 2.0), per_channel=True),\n",
        "    iaa.Grayscale(alpha=(0.0, 1.0)),\n",
        "    iaa.Fliplr(p=0.5),\n",
        "    iaa.Flipud(p=0.5),\n",
        "    iaa.Crop(percent=(0, 0.2)),\n",
        "    iaa.GaussianBlur(sigma=(0, 3.0)),\n",
        "    iaa.ElasticTransformation(alpha=(0, 5.0), sigma=0.25)\n",
        "])\n",
        "\n",
        "# Set file paths\n",
        "img_dir = \"fullDataHalftexted/train/images/\"\n",
        "label_dir = \"fullDataHalftexted/train/labels/\"\n",
        "output_img_dir = \"augImages/\"\n",
        "output_label_dir = \"augLabels/\"\n",
        "\n",
        "# Iterate through images and corresponding label files\n",
        "for filename in os.listdir(img_dir):\n",
        "    # Load image\n",
        "    img_path = os.path.join(img_dir, filename)\n",
        "    img = cv2.imread(img_path)\n",
        "    \n",
        "    # Load bounding boxes from corresponding label file\n",
        "    label_path = os.path.join(label_dir, filename[:-4] + \".txt\")\n",
        "    with open(label_path, \"r\") as f:\n",
        "        lines = f.readlines()\n",
        "    bboxes = []\n",
        "    for line in lines:\n",
        "        coords = line.strip().split()\n",
        "        # print(coords[1:])\n",
        "        x, y, w, h = [float(coord) for coord in coords[1:]]\n",
        "        # exit()\n",
        "        bbox = BoundingBox(x1=x, y1=y, x2=x+w, y2=y+h)\n",
        "        bboxes.append(bbox)\n",
        "    bboxes_on_img = BoundingBoxesOnImage(bboxes, shape=img.shape)\n",
        "    \n",
        "    # Apply augmentation sequence to image and bounding boxes\n",
        "    img_aug, bboxes_aug = aug(image=img, bounding_boxes=bboxes_on_img)\n",
        "    \n",
        "    # Save augmented image\n",
        "    output_img_path = os.path.join(output_img_dir, \"aug_\"+filename)\n",
        "    cv2.imwrite(output_img_path, img_aug)\n",
        "    \n",
        "    # Save augmented bounding boxes to label file\n",
        "    output_label_path = os.path.join(output_label_dir, filename[:-4] + \".txt\")\n",
        "    with open(output_label_path, \"w\") as f:\n",
        "        for bbox in bboxes_aug.bounding_boxes:\n",
        "            x1, y1, x2, y2 = bbox.x1, bbox.y1, bbox.x2, bbox.y2\n",
        "            f.write(\"aug_0 \" + \" \".join([str(coord) for coord in [x1, y1, x2-x1, y2-y1]]) + \"\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N75-Bnaxc3Kt",
        "outputId": "a34f6499-383b-4bd3-df9b-6a58d0f1879c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/imgaug/imgaug.py:184: DeprecationWarning: Function `ContrastNormalization()` is deprecated. Use `imgaug.contrast.LinearContrast` instead.\n",
            "  warn_deprecated(msg, stacklevel=3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(glob('fullDataHalftexted/train/images/*'))"
      ],
      "metadata": {
        "id": "GDBMMVgFfOIV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c7066bb-10bd-48fe-a10c-6aa0064ac440"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "120"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp augImages/* fullDataHalftexted/train/images/\n",
        "!cp augLabels/* fullDataHalftexted/train/labels/"
      ],
      "metadata": {
        "id": "qDTCACi7hSLm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}