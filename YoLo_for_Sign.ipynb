{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rj5ZP28YaArE"
      },
      "source": [
        "**Tasks**\n",
        "\n",
        "\n",
        "1.   See the split thing and fix that problem\n",
        "2.   do the same on thw images with text in the background\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown \"18alTGY9OgS4UxxxxhCwAagCH0\""
      ],
      "metadata": {
        "id": "NOlYYwGgU0xn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !gdown \"1WcbRCbxxxxxxfiYaS8lQjRH_SJ\""
      ],
      "metadata": {
        "id": "znVaBONPPh7H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c3LGax9gZjBs"
      },
      "outputs": [],
      "source": [
        "# downloading with text in the BG\n",
        "# !gdown '1-0lLCYjx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0PvyhHWpuwHU"
      },
      "outputs": [],
      "source": [
        "# !gdown '1HJI_4bxXUjxxxxxxN-t50c9vo'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-oFZ-krbby2t"
      },
      "outputs": [],
      "source": [
        "!unzip fullDataHalftexted.zip "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # @title Preprocessing all images\n",
        "# import cv2 \n",
        "# import numpy as np \n",
        "# import matplotlib.pyplot as plt \n",
        "# # Load the image \n",
        "# imageListTextExtracted = []\n",
        "# def textDisappear(image):\n",
        "#   # image = image[2*image.shape[0]//3:,:,:]    # uncomment for taking last 2/3rd of the image\n",
        "#   # plt.imshow(image)\n",
        "#   # plt.show()\n",
        "\n",
        "#   gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "#   # Apply adaptive thresholding\n",
        "#   thresh = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 11, 2)\n",
        "#   # Find contours\n",
        "#   contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "#   # Loop through contours\n",
        "#   for contour in contours:\n",
        "#       # Get the bounding box of the contour\n",
        "#       x, y, w, h = cv2.boundingRect(contour)\n",
        "#       # Compute the aspect ratio of the bounding box\n",
        "#       aspect_ratio = w / float(h)\n",
        "#       # Filter out contours that are too wide or too tall to be text\n",
        "#       if aspect_ratio > 5 or aspect_ratio < 0.2:\n",
        "#           continue\n",
        "#       # Get the region of interest (ROI) corresponding to the contour\n",
        "#       roi = image[y:y+h, x:x+w]\n",
        "#       # Compute the average intensity of the ROI\n",
        "#       avg_intensity = np.mean(roi)\n",
        "#       # If the average intensity is below a threshold, assume the ROI contains readable text\n",
        "#       if avg_intensity < 200:\n",
        "#           # Fill the ROI with white color\n",
        "#           cv2.rectangle(image, (x, y), (x+w, y+h), (255, 255, 255), -1)\n",
        "#       # Display the result\n",
        "#       # plt.imshow(image)\n",
        "#       imageListTextExtracted.append(image)\n",
        "#       # plt.show()\n",
        "\n",
        "# import os\n",
        "# import cv2\n",
        "# directory = '/content/fullDataHalftexted/images/'  # replace with your directory path\n",
        "# names = []\n",
        "# for filename in os.listdir(directory):\n",
        "#     if filename.endswith('.jpg') or filename.endswith('.png'):  # adjust file extensions as necessary\n",
        "#         image = cv2.imread(directory+filename)\n",
        "#         names.append(filename)\n",
        "#         # plt.imshow(image)\n",
        "#         # plt.show()\n",
        "#         textDisappear(image)\n",
        "\n",
        "# !mkdir halftextedimg\n",
        "# from PIL import Image\n",
        "# import numpy as np\n",
        "# for num,image in enumerate(imageListTextExtracted):\n",
        "#   image = Image.fromarray(np.uint8(image))\n",
        "\n",
        "# # Save the image as a PNG file\n",
        "#   image.save('halftextedimg/'+names[num])\n",
        "\n",
        "# !rm -r fullDataHalftexted/images/*\n",
        "# !mv halftextedimg/* fullDataHalftexted/images/*\n",
        "# ! rm -r halftextedimg"
      ],
      "metadata": {
        "id": "4PiOEd9LVNT8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from glob import glob\n",
        "# len(glob('/content/fullDataHalftexted/images/*'))"
      ],
      "metadata": {
        "id": "QFC9LIbYW4cg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BQVvObRvZ1xe"
      },
      "outputs": [],
      "source": [
        "# !unzip images_23rd_withText.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g8dz3nra_2pu"
      },
      "outputs": [],
      "source": [
        "# !rm -r /content/images_23rd_withText"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fY98DVjbBoRM"
      },
      "outputs": [],
      "source": [
        "# !rm -r /content/custom_cleangb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9f3BrmD_-cLQ"
      },
      "outputs": [],
      "source": [
        "# %%bash\n",
        "# mkdir images_23rd_withText/images\n",
        "# mv  images_23rd_withText/*.jpg images_23rd_withText/images\n",
        "\n",
        "# mkdir images_23rd_withText/labels\n",
        "# cp custom_cleangb/labels/*.txt images_23rd_withText/labels/\n",
        "\n",
        "# cd /content/images_23rd_withText/images/\n",
        "# rm -r 24_imagewithText.jpg 27_imagewithText.jpg 28_imagewithText.jpg 35_imagewithText.jpg 39_imagewithText.jpg "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y5u6d58R74Qt"
      },
      "outputs": [],
      "source": [
        "# %%bash\n",
        "# cd /content/custom_cleangb/images/\n",
        "# rm -r 24_image.jpg 27_image.jpg 28_image.jpg 35_image.jpg 39_image.jpg "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s4eW0DUc7q9L"
      },
      "outputs": [],
      "source": [
        "# !rm -r custom_cleangb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N12VC1y0kOkN"
      },
      "outputs": [],
      "source": [
        "# %%bash\n",
        "# rm -r custom_cleangb/test\n",
        "# rm -r custom_cleangb/train\n",
        "# rm -r custom_cleangb/val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VpszQMKGEFjd"
      },
      "outputs": [],
      "source": [
        "# # @title  Rename the lables for texted images\n",
        "# import os\n",
        "\n",
        "# # Set the directory path\n",
        "# directory_path = '/content/images_23rd_withText/labels/'\n",
        "\n",
        "# # Loop through each file in the directory\n",
        "# for filename in os.listdir(directory_path):\n",
        "#     if filename.endswith('.txt'):\n",
        "#         # Construct the new filename by adding a prefix or suffix\n",
        "#         new_filename = filename[:-10] + '_imagewithText.txt'\n",
        "#         # print(new_filename)\n",
        "#         # break\n",
        "\n",
        "#         # Rename the file\n",
        "#         os.rename(os.path.join(directory_path, filename), os.path.join(directory_path, new_filename))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oOte5JQcgIjR"
      },
      "outputs": [],
      "source": [
        "# import os\n",
        "# import random\n",
        "# import shutil\n",
        "\n",
        "# # Set the path to the directory containing the images and labels\n",
        "# data_dir = '/content/custom_cleangb/'\n",
        "# # data_dir = '/content/images_23rd_withText/'\n",
        "# data_dir = '/content/fullDataHalftexted/'\n",
        "\n",
        "\n",
        "# # Set the paths to the image and label directories\n",
        "# image_dir = os.path.join(data_dir, 'images')\n",
        "# label_dir = os.path.join(data_dir, 'labels')\n",
        "\n",
        "# # Set the proportion of data to use for training, validation, and testing\n",
        "# train_prop = 0.8\n",
        "# val_prop = 0.2\n",
        "# # test_prop = 0.2\n",
        "\n",
        "# # Create the train, validation, and test directories\n",
        "# train_dir = os.path.join(data_dir, 'train')\n",
        "# val_dir = os.path.join(data_dir, 'val')\n",
        "# # test_dir = os.path.join(data_dir, 'test')\n",
        "\n",
        "# os.makedirs(train_dir, exist_ok=True)\n",
        "# os.makedirs(os.path.join(train_dir, 'images'), exist_ok=True)\n",
        "# os.makedirs(os.path.join(train_dir, 'labels'), exist_ok=True)\n",
        "# os.makedirs(val_dir, exist_ok=True)\n",
        "# os.makedirs(os.path.join(val_dir, 'images'), exist_ok=True)\n",
        "# os.makedirs(os.path.join(val_dir, 'labels'), exist_ok=True)\n",
        "# # os.makedirs(test_dir, exist_ok=True)\n",
        "# # os.makedirs(os.path.join(test_dir, 'images'), exist_ok=True)\n",
        "# # os.makedirs(os.path.join(test_dir, 'labels'), exist_ok=True)\n",
        "\n",
        "# # Get a list of all the image files\n",
        "# image_files = [f for f in os.listdir(image_dir) if f.endswith('.jpg')]\n",
        "\n",
        "# # Shuffle the image files\n",
        "# random.shuffle(image_files)\n",
        "\n",
        "# # Calculate the number of images for each set\n",
        "# num_images = len(image_files)\n",
        "# num_train = int(num_images * train_prop)\n",
        "# num_val = int(num_images * val_prop)\n",
        "# # num_test = int(num_images * test_prop)\n",
        "\n",
        "# # Copy the images and labels to the appropriate directories\n",
        "# for i, image_file in enumerate(image_files):\n",
        "#     # Get the corresponding label file\n",
        "#     label_file = image_file.replace('.jpg', '.txt')\n",
        "#     # Set the source paths\n",
        "#     image_path = os.path.join(image_dir, image_file)\n",
        "#     label_path = os.path.join(label_dir, label_file)\n",
        "#     # Set the destination paths\n",
        "#     if i < num_train:\n",
        "#         dest_dir = train_dir\n",
        "#     else:\n",
        "#         dest_dir = val_dir\n",
        "#     dest_image_dir = os.path.join(dest_dir, 'images')\n",
        "#     dest_label_dir = os.path.join(dest_dir, 'labels')\n",
        "#     dest_image_path = os.path.join(dest_image_dir, image_file)\n",
        "#     dest_label_path = os.path.join(dest_label_dir, label_file)\n",
        "#     # Copy the files to the appropriate directories\n",
        "#     shutil.copyfile(image_path, dest_image_path)\n",
        "#     shutil.copyfile(label_path, dest_label_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Preprocessing all images\n",
        "import cv2 \n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt \n",
        "# Load the image \n",
        "imageListTextExtracted = []\n",
        "def textDisappear(image):\n",
        "  # image = image[2*image.shape[0]//3:,:,:]    # uncomment for taking last 2/3rd of the image\n",
        "  # plt.imshow(image)\n",
        "  # plt.show()\n",
        "\n",
        "  gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "  # Apply adaptive thresholding\n",
        "  thresh = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 11, 2)\n",
        "  # Find contours\n",
        "  contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "  # Loop through contours\n",
        "  for contour in contours:\n",
        "      # Get the bounding box of the contour\n",
        "      x, y, w, h = cv2.boundingRect(contour)\n",
        "      # Compute the aspect ratio of the bounding box\n",
        "      aspect_ratio = w / float(h)\n",
        "      # Filter out contours that are too wide or too tall to be text\n",
        "      if aspect_ratio > 5 or aspect_ratio < 0.2:\n",
        "          continue\n",
        "      # Get the region of interest (ROI) corresponding to the contour\n",
        "      roi = image[y:y+h, x:x+w]\n",
        "      # Compute the average intensity of the ROI\n",
        "      avg_intensity = np.mean(roi)\n",
        "      # If the average intensity is below a threshold, assume the ROI contains readable text\n",
        "      if avg_intensity < 200:\n",
        "          # Fill the ROI with white color\n",
        "          cv2.rectangle(image, (x, y), (x+w, y+h), (255, 255, 255), -1)\n",
        "  # Display the result\n",
        "  # plt.imshow(image)\n",
        "  imageListTextExtracted.append(image)\n",
        "  # plt.show()"
      ],
      "metadata": {
        "id": "puBZQRabl3bp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "directory = '/content/fullDataHalftexted/images/'  # replace with your directory path\n",
        "names = []\n",
        "for filename in os.listdir(directory):\n",
        "    if filename.endswith('.jpg') or filename.endswith('.png'):  # adjust file extensions as necessary\n",
        "        # print(directory+filename)\n",
        "        image = cv2.imread(directory+filename)\n",
        "        names.append(filename)\n",
        "        # plt.imshow(image)\n",
        "        # plt.show()\n",
        "        textDisappear(image)\n",
        "\n",
        "!mkdir halftextedimg\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "for num,image101 in enumerate(imageListTextExtracted):\n",
        "  image = Image.fromarray(np.uint8(image101))\n",
        "  # print(num)\n",
        "# Save the image as a PNG file\n",
        "  try:\n",
        "    image.save('halftextedimg/'+names[num])\n",
        "  except: \n",
        "    break \n",
        "\n",
        "!rm -r fullDataHalftexted/images/*\n",
        "!mv halftextedimg/* fullDataHalftexted/images/\n",
        "!rm -r halftextedimg\n",
        "\n",
        "from glob import glob\n",
        "len(glob('/content/fullDataHalftexted/images/*'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M2yxTNcfl7Jv",
        "outputId": "bc4e366e-92f3-43f6-988a-b1aaae1b858c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "150"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import shutil\n",
        "\n",
        "# Set the path to the directory containing the images and labels\n",
        "data_dir = '/content/custom_cleangb/'\n",
        "# data_dir = '/content/images_23rd_withText/'\n",
        "data_dir = '/content/fullDataHalftexted/'\n",
        "\n",
        "\n",
        "# Set the paths to the image and label directories\n",
        "image_dir = os.path.join(data_dir, 'images')\n",
        "label_dir = os.path.join(data_dir, 'labels')\n",
        "\n",
        "# Set the proportion of data to use for training, validation, and testing\n",
        "train_prop = 0.8\n",
        "val_prop = 0.2\n",
        "# test_prop = 0.2\n",
        "\n",
        "# Create the train, validation, and test directories\n",
        "train_dir = os.path.join(data_dir, 'train')\n",
        "val_dir = os.path.join(data_dir, 'val')\n",
        "# test_dir = os.path.join(data_dir, 'test')\n",
        "\n",
        "os.makedirs(train_dir, exist_ok=True)\n",
        "os.makedirs(os.path.join(train_dir, 'images'), exist_ok=True)\n",
        "os.makedirs(os.path.join(train_dir, 'labels'), exist_ok=True)\n",
        "os.makedirs(val_dir, exist_ok=True)\n",
        "os.makedirs(os.path.join(val_dir, 'images'), exist_ok=True)\n",
        "os.makedirs(os.path.join(val_dir, 'labels'), exist_ok=True)\n",
        "# os.makedirs(test_dir, exist_ok=True)\n",
        "# os.makedirs(os.path.join(test_dir, 'images'), exist_ok=True)\n",
        "# os.makedirs(os.path.join(test_dir, 'labels'), exist_ok=True)\n",
        "\n",
        "# Get a list of all the image files\n",
        "image_files = [f for f in os.listdir(image_dir) if f.endswith('.jpg')]\n",
        "\n",
        "# Shuffle the image files\n",
        "random.shuffle(image_files)\n",
        "\n",
        "# Calculate the number of images for each set\n",
        "num_images = len(image_files)\n",
        "num_train = int(num_images * train_prop)\n",
        "num_val = int(num_images * val_prop)\n",
        "# num_test = int(num_images * test_prop)\n",
        "\n",
        "# Copy the images and labels to the appropriate directories\n",
        "for i, image_file in enumerate(image_files):\n",
        "    # Get the corresponding label file\n",
        "    label_file = image_file.replace('.jpg', '.txt')\n",
        "    # Set the source paths\n",
        "    image_path = os.path.join(image_dir, image_file)\n",
        "    label_path = os.path.join(label_dir, label_file)\n",
        "    # Set the destination paths\n",
        "    if i < num_train:\n",
        "        dest_dir = train_dir\n",
        "    else:\n",
        "        dest_dir = val_dir\n",
        "    dest_image_dir = os.path.join(dest_dir, 'images')\n",
        "    dest_label_dir = os.path.join(dest_dir, 'labels')\n",
        "    dest_image_path = os.path.join(dest_image_dir, image_file)\n",
        "    dest_label_path = os.path.join(dest_label_dir, label_file)\n",
        "    # Copy the files to the appropriate directories\n",
        "    shutil.copyfile(image_path, dest_image_path)\n",
        "    shutil.copyfile(label_path, dest_label_path)\n"
      ],
      "metadata": {
        "id": "wO7j8tUsl9pd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir augImages\n",
        "!mkdir augLabels"
      ],
      "metadata": {
        "id": "5pzH9Y9ZmAjl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %%bash\n",
        "# rm -r augImages/*\n",
        "# rm -r augLabels/*"
      ],
      "metadata": {
        "id": "0VMd_AIImFWi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import imgaug as ia\n",
        "from imgaug import augmenters as iaa\n",
        "from imgaug.augmentables.bbs import BoundingBox, BoundingBoxesOnImage\n",
        "\n",
        "# Define augmentation sequence\n",
        "aug = iaa.OneOf([\n",
        "    iaa.Affine(rotate=(-25, 25)),\n",
        "    # iaa.Affine(rotate=(-20, 20)),\n",
        "    # iaa.Affine(rotate=(-15, 15)),\n",
        "    iaa.Affine(shear=(-8, 8)),\n",
        "    iaa.Affine(shear=(-8, 8)),\n",
        "    iaa.AdditiveGaussianNoise(scale=(0, 0.1*255)),\n",
        "    iaa.Add((-50, 50), per_channel=True),\n",
        "    iaa.Multiply((0.5, 1.5), per_channel=True),\n",
        "    iaa.ContrastNormalization((0.5, 2.0), per_channel=True),\n",
        "    iaa.Grayscale(alpha=(0.0, 1.0)),\n",
        "    iaa.Fliplr(p=0.5),\n",
        "    iaa.Flipud(p=0.5),\n",
        "    iaa.Fliplr(p=0.5),\n",
        "    iaa.Flipud(p=0.5),\n",
        "    iaa.Fliplr(p=0.5),\n",
        "    iaa.Flipud(p=0.5),\n",
        "    iaa.Crop(percent=(0, 0.2)),\n",
        "    iaa.Crop(percent=(0, 0.2)),\n",
        "    iaa.GaussianBlur(sigma=(0, 3.0)),\n",
        "    iaa.ElasticTransformation(alpha=(0, 5.0), sigma=0.25)\n",
        "])\n",
        "\n",
        "\n",
        "# Set file paths\n",
        "img_dir = \"fullDataHalftexted/train/images/\"\n",
        "label_dir = \"fullDataHalftexted/train/labels/\"\n",
        "output_img_dir = \"augImages/\"\n",
        "output_label_dir = \"augLabels/\"\n",
        "\n",
        "# Iterate through images and corresponding label files\n",
        "for filename in os.listdir(img_dir):\n",
        "    # Load image\n",
        "    img_path = os.path.join(img_dir, filename)\n",
        "    img = cv2.imread(img_path)\n",
        "    \n",
        "    # Load bounding boxes from corresponding label file\n",
        "    label_path = os.path.join(label_dir, filename[:-4] + \".txt\")\n",
        "    with open(label_path, \"r\") as f:\n",
        "        lines = f.readlines()\n",
        "    bboxes = []\n",
        "    for line in lines:\n",
        "        coords = line.strip().split()\n",
        "        # print(coords[1:])\n",
        "        x, y, w, h = [float(coord) for coord in coords[1:]]\n",
        "        # exit()\n",
        "        bbox = BoundingBox(x1=x, y1=y, x2=x+w, y2=y+h)\n",
        "        bboxes.append(bbox)\n",
        "    bboxes_on_img = BoundingBoxesOnImage(bboxes, shape=img.shape)\n",
        "    \n",
        "    # Apply augmentation sequence to image and bounding boxes\n",
        "    img_aug, bboxes_aug = aug(image=img, bounding_boxes=bboxes_on_img)\n",
        "    \n",
        "    # Save augmented image\n",
        "    output_img_path = os.path.join(output_img_dir, \"aug_\"+filename)\n",
        "    cv2.imwrite(output_img_path, img_aug)\n",
        "    \n",
        "    # Save augmented bounding boxes to label file\n",
        "    output_label_path = os.path.join(output_label_dir, \"aug_\"+filename[:-4] + \".txt\")\n",
        "    with open(output_label_path, \"w\") as f:\n",
        "        for bbox in bboxes_aug.bounding_boxes:\n",
        "            x1, y1, x2, y2 = bbox.x1, bbox.y1, bbox.x2, bbox.y2\n",
        "            f.write(\"0 \" + \" \".join([str(coord) for coord in [x1, y1, x2-x1, y2-y1]]) + \"\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NdvALXZcmGHp",
        "outputId": "d145d05b-1a38-4474-878d-0043d5f935ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/imgaug/imgaug.py:184: DeprecationWarning: Function `ContrastNormalization()` is deprecated. Use `imgaug.contrast.LinearContrast` instead.\n",
            "  warn_deprecated(msg, stacklevel=3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(os.listdir(img_dir))//2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rPusX8N4izfM",
        "outputId": "ab2ef932-9c7b-4f41-dd97-ce88f6548427"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "# import cv2\n",
        "# import numpy as np\n",
        "# import imgaug as ia\n",
        "# from imgaug import augmenters as iaa\n",
        "# from imgaug.augmentables.bbs import BoundingBox, BoundingBoxesOnImage\n",
        "\n",
        "# # Define augmentation sequence\n",
        "# aug = iaa.SomeOf(n=3, children=[\n",
        "#     iaa.Affine(rotate=(-25, 25)),\n",
        "#     # iaa.Affine(rotate=(-20, 20)),\n",
        "#     # iaa.Affine(rotate=(-15, 15)),\n",
        "#     iaa.Affine(shear=(-8, 8)),\n",
        "#     iaa.Affine(shear=(-8, 8)),\n",
        "#     iaa.AdditiveGaussianNoise(scale=(0, 0.1*255)),\n",
        "#     iaa.Add((-50, 50), per_channel=True),\n",
        "#     iaa.Multiply((0.5, 1.5), per_channel=True),\n",
        "#     iaa.ContrastNormalization((0.5, 2.0), per_channel=True),\n",
        "#     iaa.Grayscale(alpha=(0.0, 1.0)),\n",
        "#     iaa.Fliplr(p=0.5),\n",
        "#     iaa.Flipud(p=0.5),\n",
        "#     iaa.Fliplr(p=0.5),\n",
        "#     iaa.Flipud(p=0.5),\n",
        "#     iaa.Fliplr(p=0.5),\n",
        "#     iaa.Flipud(p=0.5),\n",
        "#     iaa.Crop(percent=(0, 0.2)),\n",
        "#     iaa.Crop(percent=(0, 0.2)),\n",
        "#     iaa.GaussianBlur(sigma=(0, 3.0)),\n",
        "#     iaa.ElasticTransformation(alpha=(0, 5.0), sigma=0.25)\n",
        "# ], random_order=True)\n",
        "\n",
        "\n",
        "\n",
        "# # Set file paths\n",
        "# img_dir = \"fullDataHalftexted/train/images/\"\n",
        "# label_dir = \"fullDataHalftexted/train/labels/\"\n",
        "# output_img_dir = \"augImages/\"\n",
        "# output_label_dir = \"augLabels/\"\n",
        "\n",
        "# # Iterate through images and corresponding label files\n",
        "# for filename in os.listdir(img_dir)[:len(os.listdir(img_dir))//4]:\n",
        "#     # Load image\n",
        "#     img_path = os.path.join(img_dir, filename)\n",
        "#     img = cv2.imread(img_path)\n",
        "    \n",
        "#     # Load bounding boxes from corresponding label file\n",
        "#     label_path = os.path.join(label_dir, filename[:-4] + \".txt\")\n",
        "#     with open(label_path, \"r\") as f:\n",
        "#         lines = f.readlines()\n",
        "#     bboxes = []\n",
        "#     for line in lines:\n",
        "#         coords = line.strip().split()\n",
        "#         # print(coords[1:])\n",
        "#         x, y, w, h = [float(coord) for coord in coords[1:]]\n",
        "#         # exit()\n",
        "#         bbox = BoundingBox(x1=x, y1=y, x2=x+w, y2=y+h)\n",
        "#         bboxes.append(bbox)\n",
        "#     bboxes_on_img = BoundingBoxesOnImage(bboxes, shape=img.shape)\n",
        "    \n",
        "#     # Apply augmentation sequence to image and bounding boxes\n",
        "#     img_aug, bboxes_aug = aug(image=img, bounding_boxes=bboxes_on_img)\n",
        "    \n",
        "#     # Save augmented image\n",
        "#     output_img_path = os.path.join(output_img_dir, \"aug2_\"+filename)\n",
        "#     cv2.imwrite(output_img_path, img_aug)\n",
        "    \n",
        "#     # Save augmented bounding boxes to label file\n",
        "#     output_label_path = os.path.join(output_label_dir, \"aug2_\"+filename[:-4] + \".txt\")\n",
        "#     with open(output_label_path, \"w\") as f:\n",
        "#         for bbox in bboxes_aug.bounding_boxes:\n",
        "#             x1, y1, x2, y2 = bbox.x1, bbox.y1, bbox.x2, bbox.y2\n",
        "#             f.write(\"0 \" + \" \".join([str(coord) for coord in [x1, y1, x2-x1, y2-y1]]) + \"\\n\")\n"
      ],
      "metadata": {
        "id": "_UpucuqKhzO8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(glob('fullDataHalftexted/train/images/*'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E5VGNN8QmIuN",
        "outputId": "473ea556-1930-4ce3-d549-958202c23a91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "120"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp augImages/* fullDataHalftexted/train/images/\n",
        "!cp augLabels/* fullDataHalftexted/train/labels/"
      ],
      "metadata": {
        "id": "A9N60Iu-mMiH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bkJ-zWqTFoJN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71fd9ca9-e196-4ad8-fcf2-e9707454c24f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "len(glob('/content/fullDataHalftexted/val/images/*'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1AImMSepFo2x"
      },
      "outputs": [],
      "source": [
        "# !rm -r /content/custom_cleangb\n",
        "!mv fullDataHalftexted  custom_cleangb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jeCRSaAMXHKY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b14ab3a9-e04d-4b33-f8d1-661dcae9d835"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing collected packages: sentry-sdk, thop, ultralytics\n",
            "Successfully installed sentry-sdk-1.17.0 thop-0.1.1.post2209072238 ultralytics-8.0.58\n"
          ]
        }
      ],
      "source": [
        "!pip install ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IhpadSc0lYo_",
        "outputId": "95a81bc2-4043-405e-b6bb-006762271194"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/ultralytics/datasets/coco128.yaml\n",
            "find: â€˜/proc/52/task/52/netâ€™: Invalid argument\n",
            "find: â€˜/proc/52/netâ€™: Invalid argument\n"
          ]
        }
      ],
      "source": [
        "!find / -name coco128.yaml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ghj6dBkMlgzp"
      },
      "outputs": [],
      "source": [
        "!rm /usr/local/lib/python3.9/dist-packages/ultralytics/datasets/coco128.yaml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v_S3CsD1ume-"
      },
      "outputs": [],
      "source": [
        "!gdown '1T4Azuxxxx4JgKCeHGtVI7'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4AocQlWblkaQ"
      },
      "outputs": [],
      "source": [
        "!cp coco128.yaml /usr/local/lib/python3.9/dist-packages/ultralytics/datasets/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R93r6DYtmBjf"
      },
      "outputs": [],
      "source": [
        "# !rm -r datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown \"1plK8boxxxx4NykRVjYCBVXqm\""
      ],
      "metadata": {
        "id": "2-jfIaUKoVs_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kTa8UaGrXBfk"
      },
      "outputs": [],
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Load a model\n",
        "model = YOLO('yolov8n.yaml')  # build a new model from YAML\n",
        "model = YOLO('yolov8n.pt')  # load a pretrained model (recommended for training)\n",
        "model = YOLO('yolov8n.yaml').load('yolov8n.pt')  # build from YAML and transfer weights\n",
        "\n",
        "# Train the model\n",
        "model.train(data='coco128.yaml', epochs=250, imgsz=640)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nkkmqpr7nqji",
        "outputId": "dcde52b1-d702-47c9-804b-b3e027451a1e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Ultralytics YOLOv8.0.58 ðŸš€ Python-3.9.16 torch-1.13.1+cu116 CUDA:0 (Tesla T4, 15102MiB)\n",
            "YOLOv8n summary (fused): 168 layers, 3005843 parameters, 0 gradients, 8.1 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/custom_cleangb/val/labels.cache... 30 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.09it/s]\n",
            "                   all         30         45      0.882      0.622      0.711      0.398\n",
            "Speed: 1.4ms preprocess, 3.5ms inference, 0.0ms loss, 1.7ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/val\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "metrics = model.val()  # no arguments needed, dataset and settings remembered"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/best.pt   /content/drive/MyDrive/"
      ],
      "metadata": {
        "id": "jumGWEtnZH_Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "ZQnoXQITZH3N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TwEYpu4cZHy3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "T65LUbSEZHte"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uSY9cbNNZHpN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3JAuIERIZHlH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yagk-aPCzEPA"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from PIL import Image\n",
        "from glob import glob\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UQeh52Asy-Qg"
      },
      "outputs": [],
      "source": [
        "# inputs = []\n",
        "# test_images = glob('/content/custom_cleangb/test/images/*.jpg')\n",
        "# for x in test_images:\n",
        "#   img = np.array(Image.open(x))\n",
        "#   inputs.append(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XS8qGukzw7TI"
      },
      "outputs": [],
      "source": [
        "# # inputs = [img, img]   \n",
        "# results = model(inputs)  \n",
        "\n",
        "# for result in results:\n",
        "#     res_plotted = result.plot()\n",
        "#     cv2_imshow(res_plotted)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M6JNkeswnsFy"
      },
      "outputs": [],
      "source": [
        "metrics.box.map  ,metrics.box.map50, metrics.box.map75 ,metrics.box.maps  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e8vA-UkZn0Cj"
      },
      "outputs": [],
      "source": [
        "results = model('/content/custom_cleangb/test/images/16_image.jpg')  # predict on an image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BNSFpJgOoBjo"
      },
      "outputs": [],
      "source": [
        "result = model.predict('/content/custom_cleangb/train/images/0_image.jpg')\n",
        "result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "erPFcC1Gp8fV"
      },
      "outputs": [],
      "source": [
        "result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-QyOgCuFqdxb"
      },
      "outputs": [],
      "source": [
        "import imgaug as ia\n",
        "import imgaug.augmenters as iaa\n",
        "from imgaug.augmentables.bbs import BoundingBox, BoundingBoxesOnImage\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "ia.seed(1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import imgaug.augmenters as iaa\n",
        "from imgaug.augmentables.bbs import BoundingBox, BoundingBoxesOnImage\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define the augmentations\n",
        "aug = iaa.OneOf([\n",
        "    iaa.Affine(rotate=(-25, 25)),  # rotate image by -25 to 25 degrees\n",
        "    iaa.Affine(shear=(-8, 8)),  # shear image by -8 to 8 degrees\n",
        "    iaa.AdditiveGaussianNoise(scale=(0, 0.1*255)),  # add gaussian noise with std deviation of 0 to 0.1*255\n",
        "    iaa.Add((-50, 50), per_channel=True),  # add -50 to 50 intensity to each channel\n",
        "    iaa.Multiply((0.5, 1.5), per_channel=True),  # multiply each pixel by 0.5 to 1.5\n",
        "    iaa.ContrastNormalization((0.5, 2.0), per_channel=True),  # adjust contrast of each channel by a factor of 0.5 to 2.0\n",
        "    iaa.Grayscale(alpha=(0.0, 1.0)),  # convert the image to grayscale with a probability of 0.0 to 1.0\n",
        "    iaa.Fliplr(p=0.5),  # flip the image horizontally with a probability of 0.5\n",
        "    iaa.Flipud(p=0.5),  # flip the image vertically with a probability of 0.5\n",
        "    iaa.Crop(percent=(0, 0.2)),  # crop the image by a random percentage up to 20%\n",
        "    iaa.GaussianBlur(sigma=(0, 3.0)),  # blur the image with a sigma of 0 to 3.0\n",
        "    iaa.ElasticTransformation(alpha=(0, 5.0), sigma=0.25)  # deform the image with elastic transformation\n",
        "])\n",
        "\n",
        "\n",
        "# Define a list of images and a list of corresponding bounding boxes\n",
        "images = [ia.quokka(size=(256, 256)), ia.quokka(size=(256, 256))]\n",
        "bbs_list = [    BoundingBoxesOnImage([BoundingBox(x1=65, y1=100, x2=200, y2=150)], shape=images[0].shape),\n",
        "    BoundingBoxesOnImage([BoundingBox(x1=50, y1=50, x2=150, y2=200)], shape=images[1].shape)\n",
        "]\n",
        "\n",
        "# Apply the augmentation and bounding box adjustment to each image and its corresponding bounding boxes\n",
        "aug_det = aug.to_deterministic()\n",
        "images_aug = []\n",
        "bbs_list_aug = []\n",
        "for i in range(len(images)):\n",
        "    image_aug, bbs_aug = aug_det(image=images[i], bounding_boxes=bbs_list[i])\n",
        "    images_aug.append(image_aug)\n",
        "    bbs_list_aug.append(bbs_aug)\n",
        "\n",
        "# Draw bounding boxes on the augmented images\n",
        "images_bbs_aug = []\n",
        "for i in range(len(images)):\n",
        "    images_bbs_aug.append(bbs_list_aug[i].draw_on_image(images_aug[i], size=2))\n",
        "\n",
        "# Display the augmented images with bounding boxes\n",
        "fig, axs = plt.subplots(1, len(images), figsize=(10, 5))\n",
        "for i in range(len(images)):\n",
        "    axs[i].imshow(images_bbs_aug[i])\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "S9WD309Fs1Wp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(image_bbs_aug)"
      ],
      "metadata": {
        "id": "EozjC_GAVLbn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install imgaug"
      ],
      "metadata": {
        "id": "xIM0cbtWs1TF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import imgaug as ia\n",
        "import imgaug.augmenters as iaa\n",
        "from imgaug.augmentables.bbs import BoundingBox, BoundingBoxesOnImage\n",
        "\n",
        "\n",
        "ia.seed(1)\n",
        "\n",
        "image = ia.quokka(size=(256, 256))\n",
        "bbs = BoundingBoxesOnImage([\n",
        "    BoundingBox(x1=65, y1=100, x2=200, y2=150)\n",
        "], shape=image.shape)\n",
        "\n",
        "seq = iaa.Sequential([\n",
        "    iaa.Multiply((1.2, 1.5)), # change brightness, doesn't affect BBs\n",
        "    iaa.Affine(\n",
        "        translate_px={\"x\": 40, \"y\": 60},\n",
        "        scale=(0.5, 0.7)\n",
        "    ) # translate by 40/60px on x/y axis, and scale to 50-70%, affects BBs\n",
        "])\n",
        "\n",
        "# Augment BBs and images.\n",
        "image_aug, bbs_aug = seq(image=image, bounding_boxes=bbs)\n",
        "\n",
        "# # print coordinates before/after augmentation (see below)\n",
        "# # use .x1_int, .y_int, ... to get integer coordinates\n",
        "# for i in range(len(bbs.bounding_boxes)):\n",
        "#     before = bbs.bounding_boxes[i]\n",
        "#     after = bbs_aug.bounding_boxes[i]\n",
        "#     print(\"BB %d: (%.4f, %.4f, %.4f, %.4f) -> (%.4f, %.4f, %.4f, %.4f)\" % (\n",
        "#         i,\n",
        "#         before.x1, before.y1, before.x2, before.y2,\n",
        "#         after.x1, after.y1, after.x2, after.y2)\n",
        "#     )\n",
        "\n",
        "# # image with BBs before/after augmentation (shown below)\n",
        "# image_before = bbs.draw_on_image(image, size=2)\n",
        "# image_after = bbs_aug.draw_on_image(image_aug, size=2, color=[0, 0, 255])"
      ],
      "metadata": {
        "id": "erI3T-6As1QX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bbs_aug[0]"
      ],
      "metadata": {
        "id": "9dtNtJMfuCMH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.imshow(image_before)"
      ],
      "metadata": {
        "id": "HDODz43qtPOE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "plt.imshow(image_after)"
      ],
      "metadata": {
        "id": "z-I7XGH7tPt3"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}